{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occams Razor\n",
    "\n",
    "## Neural networks, Occam's razor, and heuristic search [Blogpost]\n",
    "\n",
    "https://dselsam.github.io/neural-networks-occams-razor/\n",
    "\n",
    "#### Quotes\n",
    "\n",
    "\"Neural networks sacrifice Occamâ€™s razor in exchange for the ability to efficiently find parameters that fit the training data.\"\n",
    "\n",
    "\"In general, the best way to generalize from a finite set of training data involves finding the shortest computer program that (efficiently) explains the training data.\"\n",
    "\n",
    "\"the effects of such regularization are subtle and do not correspond to what we really want, which is to prefer parameters that behave like short computer programs. Indeed, l2 regularization does not help learn the identity function in the example above.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occam's Razor [Paper]\n",
    "\n",
    "https://papers.nips.cc/paper/1925-occams-razor.pdf\n",
    "\n",
    "Paper focusses on Occam's Razor for Bayesian models. It illustrated that in a Bayesian approach, Occam's razor is always at work.\n",
    "\n",
    "#### Quotes\n",
    "\n",
    "\"One might think that one has to build a prior over models which explicitly favours simpler models. But as we will see, Occam's Razor is in fact embodied in the application of Bayesian theory.\"\n",
    "\n",
    "\"From a non-Bayesian perspective, arguments are put forward for adjusting model complexity in the light of limited training data, to avoid over-fitting.\"\n",
    "\n",
    "\"If the model complexity is either too low or too high performance on an independent test set will suffer, giving rise to a characteristic Occam's Hill. Typically an estimator of the generalization error or an independent validation set is used to control the model complexity.\"\n",
    "\n",
    "\"Typically an estimator of the generalization error or an independent validation set is used to control the model complexity.\"\n",
    "\n",
    "\"One of the central quantities in Bayesian learning is the evidence, the probability of the data given the model P(Y | Mi) computed as the integral over the parameters W of the likelihood times the prior.\"\n",
    "\n",
    "\"In non-parametric Bayesian models there is no statistical reason to constrain models, as\n",
    "long as our prior reflects our beliefs.\"\n",
    "\n",
    "\"The ratio of prior to posterior volumes is the Occam Factor, which may be interpreted as a penalty to pay for fitting parameters.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity and Generalization in Neural Networks: an Empirical Study [Paper]\n",
    "\n",
    "https://arxiv.org/abs/1802.08760\n",
    "\n",
    "* Literatature study on complexity metrics in neural networks and measuring generalizatoin\n",
    "* Measure two aspects of sensitivity\n",
    "    1. How does the output of the network change as the input is perturbed within the linear region? -> Done with the help of \"Jacobian norm\" that measures the sensitivity of the class probabilities with respect to the samples of interest. This is done by calculating the average gradient of the predicted class for a set of test samples.\n",
    "    2. How likely is the linear region to change in response to change in the input? -> Done by using piecewise non-linearities like relu and assigning a code to each linear piece. A concatenation of all codes in the neural network describes the linear region of an input. Then different trajectories are defined. The transitions of linear regions in these trajectories are then measured.\n",
    "\n",
    "They show that the best achieved generalization is not necessarily the simplest model.\n",
    "\n",
    "Intersting paper!\n",
    "\n",
    "\n",
    "#### Quotes\n",
    "\n",
    "\"we investigate this tension between complexity and generalization through an extensive empirical exploration of two natural metrics of complexity related to sensitivity to input perturbations\"\n",
    "\n",
    "\"We find that trained neural networks are more robust to input perturbations in the vicinity of the training data manifold, as measured by the norm of the input-output Jacobian of the network, and that it correlates well with generalization.\"\n",
    "\n",
    "\"not only do large networks demonstrate good test performance, but larger networks often generalize better, counter to what would be expected from classical measures, such as VC dimension\"\n",
    "\n",
    "\"the norm of the input-output Jacobian, correlates with generalization in a very wide variety of scenarios\"\n",
    "\n",
    "\"Then we can measure two aspects of sensitivity by answering\n",
    "1. How does the output of the network change as the input is perturbed within the linear region?\n",
    "2. How likely is the linear region to change in response to change in the input?\"\n",
    "\n",
    "\"We find that, according to both the Jacobian norm and transitions metrics, functions exhibit much more robust behavior around the training data\"\n",
    "\n",
    "\"We conjecture large networks to have access to a larger space of robust solutions due to solving a highly-underdetermined system when fitting a dataset, while small models converge to more extreme weight values due to being overconstrained by the data.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
